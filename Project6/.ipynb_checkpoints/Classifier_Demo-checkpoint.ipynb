{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e408fa-30a2-4b1e-8fe8-b0059901f9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Loading cat\n",
      "Loading notcat\n",
      "creating model\n",
      "training model\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.6177 - loss: 0.7045\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.8729 - loss: 0.2906\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.9918 - loss: 0.0937\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0328\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9955 - loss: 0.0227\n",
      "Epoch 6/10\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 3s/step - accuracy: 0.9950 - loss: 0.0211"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from PIL import Image\n",
    "from random import shuffle, choice\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "IMAGE_DIRECTORY = './train'\n",
    "\n",
    "def label_img(name):\n",
    "  if name == 'cat': return np.array([1, 0])\n",
    "  elif name == 'notcat' : return np.array([0, 1])\n",
    "\n",
    "def load_data():\n",
    "  print(\"Loading images...\")\n",
    "  train_data = []\n",
    "  directories = next(os.walk(IMAGE_DIRECTORY))[1]\n",
    "\n",
    "  for dirname in directories:\n",
    "    print(\"Loading {0}\".format(dirname))\n",
    "    file_names = next(os.walk(os.path.join(IMAGE_DIRECTORY, dirname)))[2]\n",
    "\n",
    "    for i in range(200):\n",
    "      image_name = choice(file_names)\n",
    "      image_path = os.path.join(IMAGE_DIRECTORY, dirname, image_name)\n",
    "      label = label_img(dirname)\n",
    "      if \"DS_Store\" not in image_path:\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "        train_data.append([np.array(img), label])\n",
    "\n",
    "  return train_data\n",
    "\n",
    "\n",
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', \n",
    "                   input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "training_data = load_data()\n",
    "training_images = np.array([i[0] for i in training_data]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "training_labels = np.array([i[1] for i in training_data])\n",
    "\n",
    "print('creating model')\n",
    "model = create_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print('training model')\n",
    "model.fit(training_images, training_labels, batch_size=50, epochs=10, verbose=1)\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f345bcf9-4b1f-46e8-a05e-970adf142179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Loading cats\n",
      "Loading notcats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Testing model...\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 148ms/step - accuracy: 0.3732 - loss: 4.4690\n",
      "accuracy: 66.15384817123413\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from PIL import Image\n",
    "from random import shuffle, choice\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "IMAGE_DIRECTORY = './test'\n",
    "\n",
    "def label_img(name):\n",
    "    if name == 'cat': return np.array([1, 0])\n",
    "    elif name == 'notcat' : return np.array([0, 1])\n",
    "\n",
    "\n",
    "def load_data(imdir):\n",
    "  print(\"Loading images...\")\n",
    "  test_data = []\n",
    "  directories = next(os.walk(imdir))[1]\n",
    "\n",
    "  for dirname in directories:\n",
    "    print(\"Loading {0}\".format(dirname))\n",
    "    file_names = next(os.walk(os.path.join(imdir, dirname)))[2]\n",
    "    for i in range(len(file_names)):\n",
    "      image_name = choice(file_names)\n",
    "      image_path = os.path.join(imdir, dirname, image_name)\n",
    "      if image_name != \".DS_Store\":\n",
    "        label = label_img(dirname)\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "        test_data.append([np.array(img), label])\n",
    "  \n",
    "  return test_data\n",
    "\n",
    "test_data = load_data(IMAGE_DIRECTORY)\n",
    "test_images = np.array([i[0] for i in test_data]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "test_labels = np.array([i[1] for i in test_data])\n",
    "\n",
    "print('Loading model...')\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "print('Testing model...')\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=1)\n",
    "\n",
    "print(\"accuracy: {0}\".format(acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
