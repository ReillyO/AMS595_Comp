{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1e408fa-30a2-4b1e-8fe8-b0059901f9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Loading cat\n",
      "Loading notcat\n",
      "creating model\n",
      "training model\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.6177 - loss: 0.7045\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.8729 - loss: 0.2906\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.9918 - loss: 0.0937\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0328\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9955 - loss: 0.0227\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9950 - loss: 0.0211\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9988 - loss: 0.0073\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9991 - loss: 0.0068\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9978 - loss: 0.0097\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from PIL import Image\n",
    "from random import shuffle, choice\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "IMAGE_DIRECTORY = './train'\n",
    "\n",
    "# Generate a label for the image based on the directory it is in\n",
    "def label_img(name):\n",
    "  if name == 'cat': return np.array([1, 0])\n",
    "  elif name == 'notcat' : return np.array([0, 1])\n",
    "\n",
    "# Load in and preprocess the images from the directories, return an array of them with labels\n",
    "def load_data():\n",
    "  print(\"Loading images...\")\n",
    "  train_data = []\n",
    "  directories = next(os.walk(IMAGE_DIRECTORY))[1]\n",
    "\n",
    "  for dirname in directories:\n",
    "    print(\"Loading {0}\".format(dirname))\n",
    "    file_names = next(os.walk(os.path.join(IMAGE_DIRECTORY, dirname)))[2]\n",
    "\n",
    "    for i in range(200):\n",
    "      image_name = choice(file_names)\n",
    "      image_path = os.path.join(IMAGE_DIRECTORY, dirname, image_name)\n",
    "      label = label_img(dirname)\n",
    "      if \"DS_Store\" not in image_path:\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "        train_data.append([np.array(img), label])\n",
    "\n",
    "  return train_data\n",
    "\n",
    "# Create the model for binary classification of whether a cat is present\n",
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', \n",
    "                   input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "  return model\n",
    "\n",
    "# load data and convert into shape/format expected by Keras\n",
    "training_data = load_data()\n",
    "training_images = np.array([i[0] for i in training_data]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "training_labels = np.array([i[1] for i in training_data])\n",
    "\n",
    "# Train model based on the provided cat/nocat images\n",
    "print('creating model')\n",
    "model = create_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print('training model')\n",
    "model.fit(training_images, training_labels, batch_size=50, epochs=10, verbose=1)\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f345bcf9-4b1f-46e8-a05e-970adf142179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Loading cat\n",
      "Loading notcat\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "WARNING:tensorflow:6 out of the last 89 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x000001F6485AA200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 89 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x000001F6485AA200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 0.6246 - loss: 1.5398\n",
      "accuracy: 63.999998569488525\n",
      "loss: 143.56509447097778\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from PIL import Image\n",
    "from random import shuffle, choice\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set constants\n",
    "IMAGE_SIZE = 256\n",
    "IMAGE_DIRECTORY = './test'\n",
    "\n",
    "# Method for labeling image based on classification/ground truth\n",
    "def label_img(name):\n",
    "    if name == 'cat': return np.array([1, 0])\n",
    "    elif name == 'notcat' : return np.array([0, 1])\n",
    "\n",
    "# Load in images and label\n",
    "def load_data(imdir):\n",
    "  print(\"Loading images...\")\n",
    "  test_data = []\n",
    "  directories = next(os.walk(imdir))[1]\n",
    "\n",
    "  for dirname in directories:\n",
    "    print(\"Loading {0}\".format(dirname))\n",
    "    file_names = next(os.walk(os.path.join(imdir, dirname)))[2]\n",
    "    for i in range(len(file_names)):\n",
    "      image_name = choice(file_names)\n",
    "      image_path = os.path.join(imdir, dirname, image_name)\n",
    "      if image_name != \".DS_Store\":\n",
    "        label = label_img(dirname)\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "        test_data.append([np.array(img), label])\n",
    "  \n",
    "  return test_data\n",
    "\n",
    "# Load and preprocess images\n",
    "test_data = load_data(IMAGE_DIRECTORY)\n",
    "test_images = np.array([i[0] for i in test_data]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "test_labels = np.array([i[1] for i in test_data])\n",
    "\n",
    "# Load in model generated in previous step\n",
    "print('Loading model...')\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "# Assess model accuracy using Keras methods\n",
    "print('Testing model...')\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=1)\n",
    "\n",
    "print(\"accuracy: {0}\".format(acc * 100))\n",
    "print(\"loss: {0}\".format(loss * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
